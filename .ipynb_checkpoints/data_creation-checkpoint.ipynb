{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b7fe8c1-2f4d-43c6-8d1c-77f36412a62f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# from dart import ts_spikes\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a0d150a-73a9-4c46-8a99-ffcff8a8c8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GRID_SIZE = 50\n",
    "NUMBER = 1000\n",
    "BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "404728b5-d668-4f78-ac4e-d5e33202c474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latitude = np.repeat(range(GRID_SIZE),GRID_SIZE * NUMBER)\n",
    "longitude = np.tile(np.arange(GRID_SIZE),GRID_SIZE * NUMBER) \n",
    "power = np.random.random(GRID_SIZE*GRID_SIZE*NUMBER)\n",
    "df = pd.DataFrame({'latitude' : latitude, 'longitude' : longitude, 'power' :  power})\n",
    "df = df.sort_values(by = ['latitude', 'longitude'])\n",
    "df = df.reset_index(drop=True)\n",
    "df['spatial_group'] = df.index // NUMBER\n",
    "df['temporal_group'] = np.tile(np.arange(NUMBER) // BATCH_SIZE, GRID_SIZE * GRID_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3a1fed6-b005-4776-8ba7-e92dad9eeec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temporal_group  spatial_group\n",
       "0               0                [1.0, 0.010419585873241231, 0.0533207523414476...\n",
       "                1                [1.0, 0.2089137547737358, 0.08460588489754058,...\n",
       "                2                [1.0, 0.0618009460925382, -0.01171485422847017...\n",
       "                3                [1.0, -0.1993879828391588, -0.0108133345005514...\n",
       "                4                [1.0, 0.16981562021490923, 0.12905340843764562...\n",
       "                                                       ...                        \n",
       "39              2495             [1.0, -0.08842281363393534, -0.108417071027382...\n",
       "                2496             [1.0, -0.31439524431230803, 0.1669828494750995...\n",
       "                2497             [1.0, -0.2291141360491174, -0.2411010239200786...\n",
       "                2498             [1.0, -0.199784600260765, -0.06747884476746367...\n",
       "                2499             [1.0, 0.20766301882547722, 0.10372497263962041...\n",
       "Length: 100000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['temporal_group', 'spatial_group']).apply(lambda group: acf(group['power'], nlags=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "896bce34-f1c6-4931-bb94-eac109347f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_,group = next(iter(df.groupby(['temporal_group', 'spatial_group'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a717a056-6f7f-474e-986e-d29a23b39221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Different aggregate functions\n",
    "def difference_time_series(x):\n",
    "    ''''''\n",
    "    return x.diff().dropna()\n",
    "\n",
    "\n",
    "def x_acf1(x):\n",
    "    '''The autocorrelation function of the series'''\n",
    "    return acf(x, nlags=1)[1]\n",
    "\n",
    "\n",
    "def diff1_acf1(x):\n",
    "    '''The autocorrelation function of the differenced series'''\n",
    "    first_difference = difference_time_series(x)\n",
    "    return acf(first_difference, nlags=1)[1]\n",
    "\n",
    "\n",
    "def diff2_acf1(x):\n",
    "    '''The autocorrelation function of the second-order differenced series'''\n",
    "    first_difference = difference_time_series(x)\n",
    "    second_difference = difference_time_series(first_difference)\n",
    "    return acf(second_difference, nlags=1)[1]\n",
    "\n",
    "\n",
    "def e_acf1(x):\n",
    "    '''The autocorrelation function of the residuals'''\n",
    "    return acf(data - x.rolling(window=2).mean().dropna(), nlags=1)[1]\n",
    "\n",
    "\n",
    "def x_acf10(x):\n",
    "    '''The sum of squares of the first 10 autocorrelation coefficients for series'''\n",
    "    return sum(acf(group['power'], nlags=10)**2)\n",
    "\n",
    "def diff1_acf10(x):\n",
    "    '''The sum of squares of the first 10 autocorrelation coefficients for the differenced series'''\n",
    "    first_difference = difference_time_series(x)\n",
    "    return sum(acf(first_difference['power'], nlags=10)**2)\n",
    "\n",
    "def diff2_acf10(x):\n",
    "    '''The sum of squares of the first 10 autocorrelation coefficients for second-order the differenced series'''\n",
    "    x = difference_time_series(x)\n",
    "    return sum(acf(group['power'], nlags=10)**2)\n",
    "\n",
    "\n",
    "def e_acf10(x,window_size=2):\n",
    "    '''The sum of squares of the first 10 autocorrelation coefficients of the residuals'''\n",
    "    # Calculate the rolling mean\n",
    "    rolling_mean = data_pd.rolling(window=window_size).mean().dropna()\n",
    "\n",
    "    # Calculate the residuals by subtracting the rolling mean from the original data\n",
    "    residuals = data[:-window_size+1] - rolling_mean.values\n",
    "\n",
    "    # Compute the autocorrelation function for the residuals\n",
    "    e_acf = acf(residuals, nlags=10)\n",
    "\n",
    "    # Calculate the sum of squares of the first 10 autocorrelation coefficients\n",
    "    e_acf10 = np.sum(np.square(e_acf[:10]))\n",
    "\n",
    "    return e_acf10\n",
    "\n",
    "\n",
    "def entropy(x):\n",
    "    '''The spectral entropy is the Shannon entropy''''\n",
    "    return -np.sum(x * np.log2(x))\n",
    "\n",
    "\n",
    "def crossing_points(x):\n",
    "    '''The number of times the temporal data-set crosses the median line'''\n",
    "    return len(np.where(np.diff((x['power'] > x['power'].median())))[0])\n",
    "\n",
    "\n",
    "def flat_spots(x):\n",
    "    '''The temporal dataset is divided into ten equally blocks then the largest runlength represents the value of flat_spots'''\n",
    "    pass\n",
    "\n",
    "\n",
    "def nonlinear(x):\n",
    "    '''The nonlinearity is estimated from a modified Teräsvirta’s test'''\n",
    "    pass\n",
    "\n",
    "\n",
    "def linearity(x):\n",
    "    ''' The strength of curvature are estimated from the coefficients of the orthogonal quadratic regression.'''\n",
    "    pass\n",
    "\n",
    "\n",
    "def curvature(x):\n",
    "    ''''''\n",
    "    pass\n",
    "\n",
    "\n",
    "def x_pacf5(x):\n",
    "    '''Thee sum of the first 5 partial autocorrelation coefficients of the series''''\n",
    "    return np.sum(pacf(x, nlags=5)[:5])\n",
    "\n",
    "\n",
    "def diff1_pacf5(x):\n",
    "    ''''The sum of the first 5 partial autocorrelation coefficients of the differenced series'''\n",
    "    first_difference = difference_time_series(x)\n",
    "    return np.sum(pacf(first_difference, nlags=5)[:5])\n",
    "    \n",
    "\n",
    "def diff2_pacf5(x):\n",
    "    '''The sum of the first 5 partial autocorrelation coefficients of the second-order differenced series'''\n",
    "    first_difference = difference_time_series(x)\n",
    "    second_difference = difference_time_series(first_difference)\n",
    "    return np.sum(pacf(second_difference, nlags=5)[:5])\n",
    "\n",
    "\n",
    "def lumpiness(x):\n",
    "    '''Temporal dataset is divided into non-overlapping windoes the variance of the mean of the tiled windows'''\n",
    "    pass\n",
    "\n",
    "\n",
    "def stability(x):\n",
    "    '''Temporal dataset is divided into non-overlapping windoes the variance of the variance of the tiled windows'''\n",
    "    pass\n",
    "\n",
    "\n",
    "def arch_stat(x):\n",
    "    '''Stability based on Lagrange Multiplier Test'''\n",
    "    lag, arch_stat, p_value, f_test = het_arch(data, maxlag=10)\n",
    "    return arch_stat\n",
    "\n",
    "\n",
    "def trend(x):\n",
    "    '''The strength of the trend is found from Seasonal-Trend decomposition using LOESS'''\n",
    "    stl = STL(x, period=12)\n",
    "    res = stl.fit()\n",
    "\n",
    "    # calculate trend strength measure\n",
    "    trend_var, total_var = np.var(res.trend), np.var(x)\n",
    "    return trend_var / total_var\n",
    "\n",
    "\n",
    "def spike(x):\n",
    "    '''Variance of the leave-one-out variances of the residuals'''\n",
    "    model = ARIMA(x, order=(1,1,1))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # calculate residuals\n",
    "    residuals = pd.Series(model_fit.resid)\n",
    "\n",
    "    # calculate variance of residuals\n",
    "    residuals_var = np.var(residuals)\n",
    "\n",
    "    # calculate leave-one-out variances of residuals\n",
    "    loocv_variances = []\n",
    "    for i in range(len(residuals)):\n",
    "        # remove one observation from the data\n",
    "        data_loo = x.drop(data.index[i])\n",
    "        # fit ARIMA model to the leave-one-out data\n",
    "        model_loo = ARIMA(data_loo, order=(1,1,1))\n",
    "        model_fit_loo = model_loo.fit()\n",
    "        # calculate residuals of the leave-one-out model\n",
    "        residuals_loo = pd.Series(model_fit_loo.resid)\n",
    "        # calculate variance of residuals of the leave-one-out model\n",
    "        residuals_var_loo = np.var(residuals_loo)\n",
    "        # add variance to the list\n",
    "        loocv_variances.append(residuals_var_loo)\n",
    "\n",
    "    # calculate spike as the variance of the leave-one-out variances of residuals\n",
    "    spike = np.var(loocv_variances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
